{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForTokenClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load fine-tuned model\n",
    "model_path = \"../models/fine_tuned_roberta\"\n",
    "model = RobertaForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load test data\n",
    "data_path = \"../data/test_data.csv\"\n",
    "df_test = pd.read_csv(data_path)\n",
    "test_inputs = df_test['text'].tolist()\n",
    "test_labels = df_test['labels'].tolist()\n",
    "\n",
    "# Tokenize and encode test data\n",
    "tokenized_inputs = tokenizer(test_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "attention_mask = tokenized_inputs['attention_mask']\n",
    "\n",
    "# Define test data loader\n",
    "batch_size = 8\n",
    "test_data = TensorDataset(tokenized_inputs['input_ids'], attention_mask)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "# Make predictions on test set\n",
    "predictions = []\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs[0]\n",
    "    predictions.extend([list(p) for p in torch.argmax(logits, dim=2).cpu().numpy()])\n",
    "\n",
    "# Convert predictions to labels\n",
    "idx2label = {i: label for label, i in labels_dict.items()}\n",
    "predicted_labels = [[idx2label[p] for p in prediction] for prediction in predictions]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(test_labels, predicted_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "76e2935469c9cc234aefd2d7ff21ab5176d9c3335911e58cb066b21ffcbee302"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
